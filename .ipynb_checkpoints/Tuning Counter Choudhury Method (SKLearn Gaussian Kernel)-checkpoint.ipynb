{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf7ffc2e",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70799958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "import math\n",
    "import datetime, os\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from functions.common_function import *\n",
    "from functions.build_tuner_model import build_tuner_model\n",
    "from functions.dataset_interpolation import dataset_interpolation_sklearn\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "'''Enabling plotting of graphs just below the plotting commands'''\n",
    "%matplotlib inline\n",
    "'''Enabling the disply of all rows and columns within the dataframe'''\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1403514e",
   "metadata": {},
   "source": [
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce73a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature = 8\n",
    "cat_col = [4, 5]\n",
    "num_ori_feature = num_feature - len(cat_col)\n",
    "num_target = 3\n",
    "bandwidth = 100\n",
    "num_epochs = 10000\n",
    "num_folds = 4\n",
    "directory_name = \"Tuning_Counter_Choudhury_Method_SKLearn_Gaussian_Kernel\"\n",
    "\n",
    "limit = pd.DataFrame({'lower' : [303, 20, 0, 2, 6, 1.5, 122, 1236, 14], \\\n",
    "                     'higher' : [840, 44, 17, 5, 8, 2, 408, 3240, 101], \\\n",
    "                     'ref' : [530, 40, 14, 3.2, 6, 1.8, np.nan, np.nan, np.nan]})\n",
    "\n",
    "'''Importing Dataset'''\n",
    "dataset = pd.read_csv(\"Dataset/Choudhury_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314fac32",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dataset splitting before interpolation to not introduce data leakage '''\n",
    "x_train, x_test, y_train, y_test = tt_split(dataset, 0.2, num_feature, num_target)\n",
    "\n",
    "'''Merging of features and targets datasets'''\n",
    "train_dataset = merge_x_y(x_train, y_train)\n",
    "test_dataset = merge_x_y(x_test, y_test)\n",
    "\n",
    "'''Dataset Interpolation'''\n",
    "interpolated_dataset = dataset_interpolation_sklearn(train_dataset, num_ori_feature, num_target, limit)\n",
    "\n",
    "'''Converting Categorical Data into binary representation'''\n",
    "converted_dataset = convert_cat(interpolated_dataset, cat_col, num_ori_feature, num_target, [interpolated_dataset.iloc[:, 4].unique(), interpolated_dataset.iloc[:, 5].unique()])\n",
    "converted_test_dataset = convert_cat(test_dataset, cat_col, num_ori_feature, num_target, [dataset.iloc[:, 4].unique(), dataset.iloc[:, 5].unique()])\n",
    "\n",
    "'''Normalising dataset using Min Max present in the train set'''\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(converted_dataset)\n",
    "\n",
    "'''Normalisation of training and testing set'''\n",
    "normalised_train_dataset = pd.DataFrame(scaler.transform(converted_dataset), columns = get_col_names(converted_dataset))\n",
    "normalised_test_dataset = pd.DataFrame(scaler.transform(converted_test_dataset), columns = get_col_names(converted_dataset))\n",
    "\n",
    "x_train = normalised_train_dataset.iloc[:, 0: num_feature]\n",
    "y_train =  normalised_train_dataset.iloc[:, num_feature: num_feature + num_target]\n",
    "x_test = normalised_test_dataset.iloc[:, 0: num_feature]\n",
    "y_test = normalised_test_dataset.iloc[:, num_feature: num_feature + num_target]\n",
    "\n",
    "\n",
    "'''Cross Validation'''\n",
    "kfold =KFold(n_splits = num_folds, shuffle = True)\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    tuner = kt.BayesianOptimization(build_tuner_model, objective = 'val_loss', max_trials = 10, directory = 'keras_tuner', project_name = directory_name, overwrite = True)\n",
    "    tuner.search_space_summary()\n",
    "    tuner.search(x_train.iloc[train], y_train.iloc[train], epochs = num_epochs, validation_data= (x_train.iloc[test], y_train.iloc[test]))\n",
    "    tuner.results_summary()\n",
    "    best_hps = tuner.get_best_models()[0]\n",
    "    best_hps.save(f\"Model\\{directory_name}\\model_{fold_no}\")\n",
    "    print(\"Saved model to disk\")\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441830b",
   "metadata": {},
   "source": [
    "#  Loading of Models and Evaluate Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4f760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(1, 5):\n",
    "    '''Loads the Best Model Trained using Cross Validation'''\n",
    "    loaded_model = keras.models.load_model(f\"Model\\{directory_name}\\model_{i}\")\n",
    "\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    '''Compilation of the model with its corresponding weights, followed by the evaluation of the model using test set'''\n",
    "    loaded_model.compile(loss = 'MeanAbsoluteError',\\\n",
    "                        optimizer = 'SGD',\\\n",
    "                        metrics = [tf.keras.metrics.MeanSquaredError(),\\\n",
    "                        tf.keras.metrics.RootMeanSquaredError()])\n",
    "    result = loaded_model.evaluate(x_test, y_test, batch_size = 128)\n",
    "    print(f\"Mean Absolute Error for model {i}(Loss): \", result[0])\n",
    "    results.append(result[0])\n",
    "\n",
    "'''Provide average score'''\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(results)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Iteration {i+1} - MAE: {results[i]}') \n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> MAE: {np.mean(results)} - Standard Deviation: {np.std(results)}')\n",
    "print('------------------------------------------------------------------------')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236967ca",
   "metadata": {},
   "source": [
    "# Visualisation of Predictions using Best Model from Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_index = results.index(min(results)) + 1\n",
    "\n",
    "'''Loads the Best Model Trained using Cross Validation'''\n",
    "loaded_model = keras.models.load_model(f\"Model\\{directory_name}\\model_{best_model_index}\")\n",
    "\n",
    "prediction = pd.DataFrame(loaded_model.predict(x_test), columns = get_col_names(y_test))\n",
    "\n",
    "'''Preparation to Rescale target values'''\n",
    "min_y = dataset.iloc[:, num_ori_feature: num_ori_feature + num_target].min().to_list()\n",
    "max_y = dataset.iloc[:, num_ori_feature: num_ori_feature + num_target].max().to_list()\n",
    "\n",
    "corr_list = []\n",
    "'''Tabulating the differences of Expected and Predictions made by the ANN Model'''\n",
    "for i in range(len(x_test)):\n",
    "    '''Rescaling of normalised data'''\n",
    "    expected = pd.DataFrame(inverse_transform(y_test.iloc[i].to_list(), max_y, min_y))\n",
    "    predicted = pd.DataFrame(inverse_transform(prediction.iloc[i].to_list(), max_y, min_y))\n",
    "    comparison_df = pd.concat([expected, predicted], axis = 1)\n",
    "    comparison_df.columns = ['Expected', 'Predicted']\n",
    "    comparison_df.index = get_col_names(y_test)\n",
    "    display(comparison_df.style.set_caption(f\"Element {i + 1}\"))\n",
    "    corr, _ = pearsonr(expected.iloc[:, 0].tolist(), predicted.iloc[:, 0].tolist())\n",
    "    corr_list.append(corr)\n",
    "    \n",
    "'''Provide average score'''\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(corr_list)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Iteration {i+1} - Pearson Correlation: {corr_list[i]}') \n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Average Pearsons Correlation: {np.mean(corr_list)} - Standard Deviation: {np.std(corr_list)}')\n",
    "print('------------------------------------------------------------------------')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
