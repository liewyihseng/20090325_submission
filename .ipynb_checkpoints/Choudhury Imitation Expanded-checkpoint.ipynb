{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4235782",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71be131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import math\n",
    "import datetime, os\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from functions.common_function import *\n",
    "from functions.initialize_model import initialize_model_expanded\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "'''Enabling plotting of graphs just below the plotting commands'''\n",
    "%matplotlib inline\n",
    "'''Enabling the disply of all rows and columns within the dataframe'''\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff46285",
   "metadata": {},
   "source": [
    "\n",
    "# Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feature = 8\n",
    "cat_col = [4, 5]\n",
    "num_ori_feature = num_feature - len(cat_col)\n",
    "num_target = 3\n",
    "bandwidth = 100\n",
    "num_epochs = 10000\n",
    "num_batch = 10\n",
    "num_kfold = 10\n",
    "directory_name = \"Choudhury_Imitation_Expanded\"\n",
    "\n",
    "limit = pd.DataFrame({'lower' : [303, 20, 0, 2, 0, 0, 0, 0, 122, 1236, 14], \\\n",
    "                     'higher' : [840, 44, 17, 5, 1, 1, 1, 1, 408, 3240, 101], \\\n",
    "                     'ref' : [530, 40, 14, 3.2, np.nan, np.nan,np.nan, np.nan, np.nan, np.nan, np.nan]})\n",
    "\n",
    "'''Import dataset'''\n",
    "dataset = pd.read_csv(\"Dataset/Choudhury_Expanded_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeae1df",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Converting Categorical Data into binary representation'''\n",
    "converted_dataset = convert_cat(dataset, cat_col, num_ori_feature, num_target, [dataset.iloc[:, 4].unique(), dataset.iloc[:, 5].unique()])\n",
    "\n",
    "'''Normalising dataset according to higher and lower limit values'''\n",
    "normalised_dataset = normalise(converted_dataset, limit)\n",
    "\n",
    "'''Feature Target Splitting'''\n",
    "feature, target = x_y_split(normalised_dataset, num_feature, num_target)\n",
    "\n",
    "kfold = KFold(n_splits = num_kfold, shuffle = True)\n",
    "fold_no = 1\n",
    "MAE = []\n",
    "MSE = []\n",
    "RMSE = []\n",
    "\n",
    "'''Cross Validation'''\n",
    "for train, val in kfold.split(feature, target):\n",
    "    model = initialize_model_expanded(num_feature, num_target, 'sigmoid')\n",
    "    \n",
    "    '''Model Fitting'''\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "       \n",
    "    '''Initializing early stopping that prevents overfitting \n",
    "    and tensorboard for visualizing machine learning workflow'''\n",
    "    early_stopping = EarlyStopping(monitor = 'loss', mode = 'min', verbose = 1, patience = 1800)\n",
    "    logdir = os.path.join(f\"logs/{directory_name}\",\"ANN_\" + str(fold_no))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, \\\n",
    "                                                         histogram_freq = 1,\n",
    "                                                         write_graph = True,\\\n",
    "                                                         write_images = True)\n",
    "    \n",
    "    history = model.fit(feature.iloc[train],\\\n",
    "                        target.iloc[train],\n",
    "                        epochs = num_epochs,\\\n",
    "                        batch_size = num_batch,\\\n",
    "                        callbacks = [tensorboard_callback, early_stopping])\n",
    "    \n",
    "    '''Index 0 of result is represented by Mean Absolute Error'''\n",
    "    result = model.evaluate(feature.iloc[val], target.iloc[val], batch_size = 128)\n",
    "    MAE.append(result[0])\n",
    "    MSE.append(result[1])\n",
    "    RMSE.append(result[2])\n",
    "    model.save(f\"Model\\{directory_name}\\model_{fold_no}\")\n",
    "    print(\"Saved model to disk\")\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {result[0]}')\n",
    "    fold_no += 1\n",
    "\n",
    "'''Provide average score'''\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(MAE)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - MAE: {MAE[i]} - MSE: {MSE[i]}- RMSE: {RMSE[i]}') \n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> MAE: {np.mean(MAE)} - Standard Deviation: {np.std(MAE)}')\n",
    "print(f'> MSE: {np.mean(MSE)}')\n",
    "print(f'> RMSE: {np.mean(RMSE)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16007c45",
   "metadata": {},
   "source": [
    "# Loading of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db981d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loads the Best Model Trained using Cross Validation'''\n",
    "loaded_model = keras.models.load_model(f\"Model\\{directory_name}\\model_{MAE.index(min(MAE)) + 1}\")\n",
    "\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "'''Compilation of the model with its corresponding weights, followed by the evaluation of the model using test set'''\n",
    "loaded_model.compile(loss = 'MeanAbsoluteError',\\\n",
    "                    optimizer = 'SGD',\\\n",
    "                    metrics = [tf.keras.metrics.MeanSquaredError(),\\\n",
    "                    tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a704c6f",
   "metadata": {},
   "source": [
    "# Visualisation of Predictions using Best Model from Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f41b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(loaded_model.predict(feature), columns = get_col_names(target))\n",
    "\n",
    "'''Preparation to Rescale target values'''\n",
    "min_y = limit.iloc[num_feature: num_feature + num_target, 0].to_list()\n",
    "max_y = limit.iloc[num_feature: num_feature + num_target, 1].to_list()\n",
    "\n",
    "corr_list = []\n",
    "'''Tabulating the differences of Expected and Predictions made by the ANN Model'''\n",
    "for i in range(len(feature)):\n",
    "    '''Rescaling of normalised data'''\n",
    "    expected = pd.DataFrame(inverse_transform(target.iloc[i].to_list(), max_y, min_y))\n",
    "    predicted = pd.DataFrame(inverse_transform(prediction.iloc[i].to_list(), max_y, min_y))\n",
    "    comparison_df = pd.concat([expected, predicted], axis = 1)\n",
    "    comparison_df.columns = ['Expected', 'Predicted']\n",
    "    comparison_df.index = get_col_names(target)\n",
    "    display(comparison_df.style.set_caption(f\"Element {i + 1}\"))\n",
    "    corr, _ = pearsonr(expected.iloc[:, 0].tolist(), predicted.iloc[:, 0].tolist())\n",
    "    corr_list.append(corr)\n",
    "\n",
    "'''Provide average score'''\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(corr_list)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Iteration {i+1} - Pearson Correlation: {corr_list[i]}') \n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Average Pearsons Correlation: {np.mean(corr_list)} - Standard Deviation: {np.std(corr_list)}')\n",
    "print('------------------------------------------------------------------------')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
